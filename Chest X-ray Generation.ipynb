{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "9f5S1UCJ3VA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential, Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Input, Dense, BatchNormalization, Conv2D, Conv2DTranspose, ReLU, LeakyReLU, Flatten, MaxPooling2D, Dropout, Reshape"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "mwPYnr8B3VA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPU Initialization"
      ],
      "metadata": {
        "id": "7hhKcq6w3VBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "strategy = tf.distribute.MirroredStrategy()\n",
        "print('DEVICES AVAILABLE: {}'.format(strategy.num_replicas_in_sync))"
      ],
      "metadata": {
        "trusted": true,
        "id": "30GCvHVg3VBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialization"
      ],
      "metadata": {
        "id": "gLDXH6123VBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#initially I went for 128*128, later decided to go with 512*512 image size\n",
        "BUFFER_SIZE = 64000\n",
        "BATCH_SIZE = 32*strategy.num_replicas_in_sync\n",
        "batch_size = BATCH_SIZE\n",
        "EPOCHS = 50\n",
        "latent_dim = 128\n",
        "input_size = [256*2, 256*2, 3]\n",
        "image_size = (256*2, 256*2)"
      ],
      "metadata": {
        "trusted": true,
        "id": "SNXy31033VBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "lpoVSuth3VBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating dataset with ImageDataGenerator is way simpler than other methods\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "# Initially created the datatest with some augmentation, then realised, bad idea.\n",
        "#     shear_range=0.2,\n",
        "#     zoom_range=0.2,\n",
        "#     horizontal_flip=True\n",
        ")\n",
        "\n",
        "image_directory = 'chest-xray-pneumonia/chest_xray'\n",
        "\n",
        "dataset= datagen.flow_from_directory(\n",
        "    os.path.join(image_directory, 'train'),\n",
        "    classes=['PNEUMONIA'],\n",
        "    target_size=image_size,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=True\n",
        ")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "BQZvULYD3VBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "trusted": true,
        "id": "MItt-W1U3VBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generator Model"
      ],
      "metadata": {
        "id": "9GyKi7923VBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_model():\n",
        "    #in case you get OOM error, change the filter size, set it to a smaller value, 28 for example\n",
        "    model = Sequential([\n",
        "        Input(shape = (latent_dim,)),\n",
        "        Dense(8*8*256),\n",
        "        Reshape((8, 8, 256)),\n",
        "        Conv2DTranspose(128*2, kernel_size = 4, strides = 2, padding = 'same'),\n",
        "        LeakyReLU(alpha=0.1),\n",
        "        Conv2DTranspose(128*3, kernel_size=4, strides=2, padding='same'),\n",
        "        LeakyReLU(alpha=0.1),\n",
        "        Conv2DTranspose(128*3, kernel_size=4, strides=2, padding='same'),\n",
        "        LeakyReLU(alpha=0.1),\n",
        "        Conv2DTranspose(128*4, kernel_size=4, strides=2, padding='same'),\n",
        "        LeakyReLU(alpha=0.1),\n",
        "        Conv2DTranspose(128*5, kernel_size=4, strides=2, padding='same'),\n",
        "        LeakyReLU(alpha=0.1),\n",
        "        Conv2DTranspose(128*6, kernel_size=4, strides=2, padding='same'),\n",
        "        LeakyReLU(alpha=0.1),\n",
        "        Conv2D(3, kernel_size =4, padding = 'same', activation = 'sigmoid')\n",
        "    ],\n",
        "        name = \"generator\"\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "trusted": true,
        "id": "CwhGZB5E3VBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discriminator Model"
      ],
      "metadata": {
        "id": "it3KAV_F3VBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def disc_model():\n",
        "    #in case you get OOM error, change the filter size, set it to a smaller value, 256 or lower for example\n",
        "    #keep reducing that value untill the error goes away.\n",
        "    model = Sequential([\n",
        "        Input(shape = input_size),\n",
        "        Conv2D(256, kernel_size = 4, strides= 2, padding = 'same'),\n",
        "        BatchNormalization(),\n",
        "        LeakyReLU(alpha=0.1),\n",
        "        MaxPooling2D(strides = 2),\n",
        "        Conv2D(256*2, kernel_size=4, strides=2, padding='same'),\n",
        "        BatchNormalization(),\n",
        "        LeakyReLU(alpha=0.1),\n",
        "        MaxPooling2D(strides=2),\n",
        "        Conv2D(256*3, kernel_size=4, strides=2, padding='same'),\n",
        "        BatchNormalization(),\n",
        "        LeakyReLU(alpha=0.1),\n",
        "        MaxPooling2D(strides=2),\n",
        "        Conv2D(256*4, kernel_size=4, strides=2, padding='same'),\n",
        "        BatchNormalization(),\n",
        "        LeakyReLU(alpha=0.1),\n",
        "        MaxPooling2D(strides=2),\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(256*4),\n",
        "        LeakyReLU(alpha=0.1),\n",
        "        Dropout(0.2),\n",
        "        Dense(1, activation = 'sigmoid')\n",
        "    ],\n",
        "        name = \"discriminator\"\n",
        "    )\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "aq6d5pgn3VBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    #In order to utilize mutliple GPU,\n",
        "    #you  must declare model, optimizers and checkpoints inside of a scope\n",
        "    generator = gen_model()\n",
        "    discriminator = disc_model()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "HBMZHL3L3VBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator.summary()\n",
        "discriminator.summary()"
      ],
      "metadata": {
        "trusted": true,
        "id": "Wjfg_OQn3VBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#helper funtion to help us with loadidng images in batches\n",
        "def image_loader(generator):\n",
        "    for images, labels in generator:\n",
        "        yield images, labels"
      ],
      "metadata": {
        "trusted": true,
        "id": "kTwTDZhI3VBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GAN with Custom Traning Step"
      ],
      "metadata": {
        "id": "QMgcu0WV3VBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#gan model with custom gradient calculation\n",
        "class Gan(Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super().__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def compile(self, disc_opt, gen_opt, loss_function):\n",
        "        super().compile()\n",
        "        self.disc_opt = disc_opt\n",
        "        self.gen_opt = gen_opt\n",
        "        self.loss_function = loss_function\n",
        "        self.disc_loss_metric = tf.keras.metrics.Mean(name = \"disc_loss\")\n",
        "        self.gen_loss_metric = tf.keras.metrics.Mean(name = \"gen_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.disc_loss_metric, self.gen_loss_metric]\n",
        "\n",
        "    #custom training step\n",
        "    def train_step(self, data):  # Modify the function to accept labels separately\n",
        "        real_images, real_labels = data\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Fake image decoding\n",
        "        generated_images = self.generator(random_latent_vectors)\n",
        "\n",
        "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
        "\n",
        "        # Concatenate the real and fake labels\n",
        "        labels = tf.concat(\n",
        "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
        "        )\n",
        "\n",
        "\n",
        "        labels += 0.05*tf.random.uniform(tf.shape(labels))\n",
        "\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(combined_images)\n",
        "            disc_loss = self.loss_function(labels, predictions)\n",
        "\n",
        "        grads  = tape.gradient(disc_loss, self.discriminator.trainable_weights)\n",
        "        self.disc_opt.apply_gradients(\n",
        "            zip(grads, self.discriminator.trainable_weights)\n",
        "        )\n",
        "\n",
        "\n",
        "        random_latent_vectors = tf.random.normal(shape = (batch_size,self.latent_dim))\n",
        "\n",
        "        misleading_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
        "\n",
        "            gen_loss = self.loss_function(misleading_labels, predictions)\n",
        "\n",
        "        grads = tape.gradient(gen_loss, self.generator.trainable_weights)\n",
        "        self.gen_opt.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "        self.disc_loss_metric.update_state(disc_loss)\n",
        "        self.gen_loss_metric.update_state(gen_loss)\n",
        "        return{\n",
        "            \"disc_loss\": self.disc_loss_metric.result(),\n",
        "            \"gen_loss\": self.gen_loss_metric.result()\n",
        "        }\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "vQAeUxTo3VBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#helper functiont to generated a image using current generator model\n",
        "#It was initially desgined to use inside of a  callback, but can be used outside of that too.\n",
        "#Use 1 as defalut parameter when calling independently.\n",
        "def gen_images(current_epoch):\n",
        "    noise = tf.random.normal([2, latent_dim])\n",
        "    num_of_sample = 2\n",
        "    generated_images = generator(noise, training = False)\n",
        "    figure = plt.figure(figsize=(20,20))\n",
        "    for i in range(generated_images.shape[0]):\n",
        "        plt.subplot(2, 2,i+1)\n",
        "        plt.imshow(generated_images[i, :, :, 0, ], cmap = 'gray')\n",
        "        plt.title(f\"After epoch {current_epoch}\")\n",
        "        plt.axis('off')\n",
        "    plt.savefig('After epochs{:04d}.png'.format(current_epoch))\n",
        "    plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "wPs88U893VBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Callbacks"
      ],
      "metadata": {
        "id": "pFoSz-BI3VBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#callbacks. We are showing progress of gan and also saving samples after each epochs\n",
        "class Gan_Callback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, num_images=2, latent_dim = 128):\n",
        "        self.num_images = num_images\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs =None):\n",
        "        latent_vectors = tf.random.normal(shape = (self.num_images, latent_dim))\n",
        "        generated_images = self.model.generator(latent_vectors)\n",
        "        generated_images *=255\n",
        "        generated_images.numpy()\n",
        "        figure = plt.figure(figsize=(10,10))\n",
        "        for i in range(generated_images.shape[0]):\n",
        "            plt.subplot(2, 2,i+1)\n",
        "            plt.imshow(generated_images[i, :, :, 0, ], cmap='gray')\n",
        "            plt.title(f\"After epoch {epoch+1}\")\n",
        "            plt.axis('off')\n",
        "        plt.savefig('After epochs{:04d}.png'.format(epoch+1))\n",
        "        plt.show()\n",
        "        if(epoch % 10 ==0):\n",
        "            self.model.generator.save('gen.h5')\n",
        "            self.model.discriminator.save('disc.h5')"
      ],
      "metadata": {
        "trusted": true,
        "id": "vG2IJB4U3VBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    #In order to utilize mutliple GPU,\n",
        "    #you  must declare model, optimizers and checkpoints inside of a scope\n",
        "    gan = Gan(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
        "    gan.compile(\n",
        "        disc_opt=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n",
        "        gen_opt=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n",
        "        # Parallel gpu computing won't work unless  we pass reduction=tf.keras.losses.Reduction.NONE as a parameter too.\n",
        "        loss_function=tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE),\n",
        "    )\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "_nVoyKBb3VBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Traning"
      ],
      "metadata": {
        "id": "feDxo4A63VBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#actual traing begins here\n",
        "history = gan.fit(\n",
        "    image_loader(dataset),\n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch=len(dataset),\n",
        "    callbacks=[Gan_Callback(num_images=4, latent_dim=latent_dim)]\n",
        ")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "oK7sgK4b3VBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "A7w-L-91xEvj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generates Samples and Visual Inspections"
      ],
      "metadata": {
        "id": "rmOnKF35xVm3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_save_images(model, epoch, latent_dim, num_examples=4):\n",
        "    random_latent_vectors = tf.random.normal(shape=(num_examples, latent_dim))\n",
        "    generated_images = model.generator(random_latent_vectors)\n",
        "    generated_images *= 255\n",
        "    generated_images = generated_images.numpy()\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for i in range(num_examples):\n",
        "        plt.subplot(2, 2, i + 1)\n",
        "        plt.imshow(generated_images[i, :, :, 0], cmap='gray')\n",
        "        plt.title(f\"Generated Image {i+1}\")\n",
        "        plt.axis('off')\n",
        "    plt.savefig(f'generated_image_epoch_{epoch+1}.png')\n",
        "    plt.show()\n",
        "\n",
        "# Example usage after training\n",
        "generate_and_save_images(gan, EPOCHS, latent_dim)"
      ],
      "metadata": {
        "id": "di0E7hC83VBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quantitative Metrics"
      ],
      "metadata": {
        "id": "gXu5bgrlxP8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.linalg import sqrtm\n",
        "from numpy import cov, trace, iscomplexobj\n",
        "\n",
        "def calculate_fid(real_images, generated_images):\n",
        "    # Calculate mean and covariance statistics\n",
        "    mu1, sigma1 = real_images.mean(axis=0), cov(real_images, rowvar=False)\n",
        "    mu2, sigma2 = generated_images.mean(axis=0), cov(generated_images, rowvar=False)\n",
        "    # Calculate sum squared difference between means\n",
        "    ssdiff = np.sum((mu1 - mu2)**2.0)\n",
        "    # Calculate sqrt of product between covariances\n",
        "    covmean = sqrtm(sigma1.dot(sigma2))\n",
        "    # Check and correct imaginary numbers from sqrtm\n",
        "    if iscomplexobj(covmean):\n",
        "        covmean = covmean.real\n",
        "    # Calculate FID\n",
        "    fid = ssdiff + trace(sigma1 + sigma2 - 2.0 * covmean)\n",
        "    return fid\n",
        "\n",
        "# Example usage\n",
        "# real_images and generated_images should be numpy arrays of shape (num_samples, height, width, channels)\n",
        "fid_score = calculate_fid(real_images, generated_images)\n",
        "print(f'FID Score: {fid_score}')"
      ],
      "metadata": {
        "id": "U0mQJ9OqxpnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tuning"
      ],
      "metadata": {
        "id": "cNsZPxASxqut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of changing learning rates for fine-tuning\n",
        "gan.compile(\n",
        "    disc_opt=tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.5),\n",
        "    gen_opt=tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.5),\n",
        "    loss_function=tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n",
        ")\n",
        "\n",
        "# Continue training with new hyperparameters\n",
        "history = gan.fit(\n",
        "    image_loader(dataset),\n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch=len(dataset),\n",
        "    callbacks=[Gan_Callback(num_images=4, latent_dim=latent_dim)]\n",
        ")"
      ],
      "metadata": {
        "id": "Gt3v0Xznx0Z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save and Export the model"
      ],
      "metadata": {
        "id": "ouTjP7lFx5_x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save model Weighs"
      ],
      "metadata": {
        "id": "KI0KnTxDyBWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the generator and discriminator models\n",
        "generator.save('generator_model.h5')\n",
        "discriminator.save('discriminator_model.h5')"
      ],
      "metadata": {
        "id": "6DDooANjyGFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Export model"
      ],
      "metadata": {
        "id": "wyVvaLBAyGWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the entire GAN model\n",
        "gan.save('gan_model.h5')"
      ],
      "metadata": {
        "id": "p3FYuZGYyITG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}